{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.gpu.set_per_process_memory_fraction(0.3)\n",
    "tf.config.gpu.set_per_process_memory_growth(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##image loader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def path_loader(fold1, fold2, data_path):\n",
    "    #Creating data path\n",
    "    image_data_path = os.path.join(data_path, fold1)   \n",
    "    mask_data_path = os.path.join(data_path, fold2)\n",
    "    images = []\n",
    "    masks = []\n",
    "    #Listing all file names in the path\n",
    "\n",
    "    \n",
    "    for root, dirs, files in os.walk(image_data_path):\n",
    "        for name in files:\n",
    "            images.append(os.path.join(image_data_path,name))\n",
    "            \n",
    "    for root2, dirs2, files2 in os.walk(mask_data_path):\n",
    "        for name2 in files2:\n",
    "            masks.append(os.path.join(mask_data_path,name2))\n",
    "    images.sort()\n",
    "    masks.sort()\n",
    "            \n",
    "\n",
    "    return images, masks\n",
    "    \n",
    "\n",
    "# reading and resizing the training images with their corresponding labels\n",
    "def get_train_data_shuffled(images, masks, p):\n",
    "    \n",
    "\n",
    "    images, masks = shuffle(images,masks)\n",
    "    \n",
    "    #train_x, test_x, train_y, test_y = train_test_split(images,masks,test_size = p)\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "def data_loader(fold1, fold2, data_path, p,img_h, img_w):\n",
    "    \n",
    "    images, masks = path_loader(fold1, fold2, data_path)\n",
    "    train_x, train_y = get_train_data_shuffled(images, masks, p)\n",
    "    \n",
    "    train_img = []\n",
    "    train_mask = []\n",
    "    test_img = []\n",
    "    test_mask = []\n",
    "    len(train_x)\n",
    "    for i in range(len(train_x)):\n",
    "        image_name = train_x[i]\n",
    "        img = imread(image_name, as_grey=True)\n",
    "        img = resize(img, (img_h, img_w), anti_aliasing = False,preserve_range=True, order = 0).astype('float32')\n",
    "        train_img.append([np.array(img)]) \n",
    "        \n",
    "        mask_name = train_y[i]\n",
    "        mask = imread(mask_name, as_grey=True)\n",
    "        mask = resize(mask, (img_h, img_w), anti_aliasing = False,preserve_range=True, order = 0).astype('float32')\n",
    "        train_mask.append([np.array(mask)])\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print('Reading: {0}/{1}  of train images'.format(i, len(train_x)))\n",
    "            print(\"Readin image {} and mask {}\".format(image_name,mask_name))\n",
    "    return train_img, train_mask\n",
    "\"\"\"\n",
    "    for j in range(len(train_y)):\n",
    "        mask_name = train_y[j]\n",
    "        mask = imread(mask_name, as_grey=True)\n",
    "        mask = resize(mask, (img_h, img_w), anti_aliasing = False,preserve_range=True, order = 0).astype('float32')\n",
    "        train_mask.append([np.array(mask)])\n",
    "    \"\"\"\n",
    "        \n",
    "        \n",
    " \n",
    "   \n",
    "\n",
    "# Instantiating images and labels for the model.\n",
    "def get_train_test_data(fold1, fold2, data_path, p,img_h, img_w):\n",
    "    \n",
    "    train_img, train_mask = data_loader(fold1, fold2, data_path, p,img_h, img_w)\n",
    "\n",
    "    Train_Img = np.zeros((len(train_img), img_h, img_w), dtype = np.float32)\n",
    "    Train_Label = np.zeros((len(train_mask),img_h, img_w), dtype = np.int32)\n",
    "    Weight_Map = np.zeros((len(train_mask),img_h, img_w), dtype = np.int32)\n",
    "    \n",
    "    for i in range(len(train_img)):\n",
    "        Train_Img[i] = train_img[i][0]\n",
    "        mask_semi = train_mask[i][0]\n",
    "        mask_semi[mask_semi>0]=1\n",
    "        Train_Label[i] = mask_semi\n",
    "        Weight_Map[i] = create_weight_map(Train_Label[i], 2, i)\n",
    "    \n",
    "    Train_Img = np.expand_dims(Train_Img, axis = 3)  \n",
    "    Train_Label = np.expand_dims(Train_Label, axis = 3) \n",
    "\n",
    "    \n",
    "    print(Train_Img.shape)\n",
    "   \n",
    "    return Train_Img, Train_Label, Weight_Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/io/_io.py:48: UserWarning: `as_grey` has been deprecated in favor of `as_gray`\n",
      "  warn('`as_grey` has been deprecated in favor of `as_gray`')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: 0/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_CBICA_ASW_1_t1ce_53.png and mask /Lab1/Lab3/MRI/Mask/Brats17_CBICA_ASW_1_t1ce_53_Tumor.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f197d7b863b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-0004ee0e79fc>\u001b[0m in \u001b[0;36mget_train_test_data\u001b[0;34m(fold1, fold2, data_path, p, img_h, img_w)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_train_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mtrain_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mTrain_Img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-0004ee0e79fc>\u001b[0m in \u001b[0;36mdata_loader\u001b[0;34m(fold1, fold2, data_path, p, img_h, img_w)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mmask_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_grey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manti_aliasing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreserve_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mtrain_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                (plugin, kind))\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_read_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/imageio/core/format.py\u001b[0m in \u001b[0;36msearch_read_format\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;31m# Select the first that can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_formats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/imageio/core/format.py\u001b[0m in \u001b[0;36mcan_read\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mGet\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mformat\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mread\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcan_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/imageio/plugins/pillow.py\u001b[0m in \u001b[0;36m_can_read\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mfactory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPEN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugin_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0maccept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirstbytes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirstbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36mfirstbytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \"\"\"\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_firstbytes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_first_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_firstbytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_read_first_bytes\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;31m# Read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_firstbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_n_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m             \u001b[0;31m# Set back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36mread_n_bytes\u001b[0;34m(f, N)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mextra_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextra_bytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "p = 0.2\n",
    "path = '/Lab1/Lab3/MRI/'\n",
    "fold1 = 'Image'\n",
    "fold2 = 'Mask'\n",
    "image_size = 240\n",
    "\n",
    "train,test, weight = get_train_test_data(fold1, fold2, path, p,image_size, image_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(train[300,:,:,0])\n",
    "plt.colorbar()\n",
    "\n",
    "a = plt.figure(figsize=(4,4))\n",
    "plt.imshow(test[300,:,:,0])\n",
    "plt.colorbar()\n",
    "a.savefig('/Plots/Task1/Test.png')\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(weight[300,:,:])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data Augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "\n",
    "def DataAugmentation(rotation_range,width_shift,height_shift_range,rescale,horizontal_flip):\n",
    "    \n",
    "    #Train data\n",
    "    train_datagen = ImageDataGenerator(rotation_range = rotation_range, width_shift_range = width_shift, height_shift_range=height_shift_range,\n",
    "                                       horizontal_flip = horizontal_flip, rescale = rescale)\n",
    "   \n",
    "    #Val data\n",
    "    val_datagen = ImageDataGenerator(rescale = rescale)\n",
    " \n",
    "    \n",
    "    \n",
    "    return train_datagen, val_datagen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarity metrics\n",
    "from tensorflow.keras import backend as K\n",
    "smooth = 1.\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    #y_true_f = K.flatten(y_true)\n",
    "    #y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred,axis = [1,2,3])\n",
    "    return K.mean((2. * intersection + smooth) / (K.sum(y_true, axis = [1,2,3]) + K.sum(y_pred, axis = [1,2,3]) + smooth), axis = 0)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, Input, concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, SpatialDropout2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "def u_net(Base,img_height, img_width, img_ch, batchNormalization, SDRate, spatial_dropout, final_neurons, final_afun):\n",
    "    inputs = Input((img_height, img_width, img_ch))\n",
    "    inputs2 = Input((img_height, img_width, img_ch))\n",
    "    \n",
    "    ## Contraction\n",
    "    # Conv Block 1\n",
    "    \n",
    "    c1 = Conv2D(filters=Base,\n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c1 = BatchNormalization(axis=-1)(c1)\n",
    "    \n",
    "    a1 = Activation('relu')(c1)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a1 = SpatialDropout2D(SDRate)(a1)\n",
    "        \n",
    "    c2 = Conv2D(filters=Base,\n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(a1)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c2 = BatchNormalization(axis=-1)(c2)\n",
    "    \n",
    "    a2 = Activation('relu')(c2)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a2 = SpatialDropout2D(SDRate)(a2)\n",
    "        \n",
    "    m1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(a2)\n",
    "        \n",
    "    # Conv Block 2\n",
    "    c3 = Conv2D(filters=Base*2,\n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(m1)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c3 = BatchNormalization(axis=-1)(c3)\n",
    "    \n",
    "    a3 = Activation('relu')(c3)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a3 = SpatialDropout2D(SDRate)(a3)\n",
    "    \n",
    "    c4 = Conv2D(filters=Base*2,\n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(a3)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c4 = BatchNormalization(axis=-1)(c4)\n",
    "    \n",
    "    a4 = Activation('relu')(c4)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a4 = SpatialDropout2D(SDRate)(a4)\n",
    "    \n",
    "    m2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(a4)\n",
    "    \n",
    "    # Conv Block 3\n",
    "    c5 = Conv2D(filters=Base*4, \n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(m2)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c5 = BatchNormalization(axis=-1)(c5)\n",
    "    \n",
    "    a5 = Activation('relu')(c5)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a5 = SpatialDropout2D(SDRate)(a5)\n",
    "        \n",
    "    c6 = Conv2D(filters=Base*4,\n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(a5)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "          c6 = BatchNormalization(axis=-1)(c6)\n",
    "    \n",
    "    a6 = Activation('relu')(c6)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a6 = SpatialDropout2D(SDRate)(a6)\n",
    "        \n",
    "    m3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(a6)\n",
    "    \n",
    "    # Conv Block 4\n",
    "    c7 = Conv2D(filters=Base*8, \n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(m3)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c7 = BatchNormalization(axis=-1)(c7)\n",
    "    \n",
    "    a7 = Activation('relu')(c7)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a7 = SpatialDropout2D(SDRate)(a7)\n",
    "        \n",
    "    c8 = Conv2D(filters=Base*8,\n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(a7)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c8 = BatchNormalization(axis=-1)(c8)\n",
    "    \n",
    "    a8 = Activation('relu')(c8)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a8 = SpatialDropout2D(SDRate)(a8)\n",
    "        \n",
    "    m4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(a8)\n",
    "    \n",
    "    ##Bottleneck\n",
    "    # Conv Layer\n",
    "    c9 = Conv2D(filters=Base*16, \n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(m4)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c9 = BatchNormalization(axis=-1)(c9)\n",
    "    \n",
    "    a9 = Activation('relu')(c9)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a9 = SpatialDropout2D(SDRate)(a9)\n",
    "        \n",
    "    ##Expansion\n",
    "    #Conv Block 1\n",
    "    c10 = Conv2DTranspose(filters=Base*8,\n",
    "                     kernel_size=(2,2), strides=(2,2), padding='same')(a9)\n",
    "    c10 = concatenate([a8,c10])\n",
    "    \n",
    "    c11 = Conv2D(filters=Base*8,\n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(c10)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c11 = BatchNormalization(axis=-1)(c11)\n",
    "    \n",
    "    a10 = Activation('relu')(c11)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a10 = SpatialDropout2D(SDRate)(a10)\n",
    "        \n",
    "    c12 = Conv2D(filters=Base*8, \n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(a10)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c12 = BatchNormalization(axis=-1)(c12)\n",
    "    \n",
    "    a11 = Activation('relu')(c12)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a11 = SpatialDropout2D(SDRate)(a11)\n",
    "        \n",
    "    \n",
    "    #Conv Block 2\n",
    "    c13 = Conv2DTranspose(filters=Base*4,\n",
    "                     kernel_size=(2,2), strides=(2,2), padding='same')(a11)\n",
    "    c13 = concatenate([a6,c13])\n",
    "    \n",
    "    c14 = Conv2D(filters=Base*4,\n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(c13)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c14 = BatchNormalization(axis=-1)(c14)\n",
    "    \n",
    "    a12 = Activation('relu')(c14)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a12 = SpatialDropout2D(SDRate)(a12)\n",
    "        \n",
    "    c15 = Conv2D(filters=Base*4, \n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(a12)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c15 = BatchNormalization(axis=-1)(c15)\n",
    "    \n",
    "    a13 = Activation('relu')(c15)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a13 = SpatialDropout2D(SDRate)(a13)\n",
    "        \n",
    "    \n",
    "    #Conv Block 3\n",
    "    c16 = Conv2DTranspose(filters=Base*2,\n",
    "                     kernel_size=(2,2), strides=(2,2), padding='same')(a13)\n",
    "    c16 = concatenate([a4,c16])\n",
    "    \n",
    "    c17 = Conv2D(filters=Base*2, \n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(c16)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c17 = BatchNormalization(axis=-1)(c17)\n",
    "    \n",
    "    a14 = Activation('relu')(c17)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a14 = SpatialDropout2D(SDRate)(a14)\n",
    "        \n",
    "    c18 = Conv2D(filters=Base*2,\n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(a14)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c18 = BatchNormalization(axis=-1)(c18)\n",
    "    \n",
    "    a15 = Activation('relu')(c18)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a15 = SpatialDropout2D(SDRate)(a15)\n",
    "        \n",
    "    \n",
    "    #Conv Block 4\n",
    "    c19 = Conv2DTranspose(filters=Base,\n",
    "                     kernel_size=(2,2), strides=(2,2), padding='same')(a15)\n",
    "    c19 = concatenate([a2,c19])\n",
    "    \n",
    "    c20 = Conv2D(filters=Base,\n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(c19)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c20 = BatchNormalization(axis=-1)(c20)\n",
    "    \n",
    "    a16 = Activation('relu')(c20)\n",
    "    \n",
    "    #Add spatial Dropout\n",
    "    if spatial_dropout:\n",
    "        a16 = SpatialDropout2D(SDRate)(a16)\n",
    "        \n",
    "    c21 = Conv2D(filters=Base,\n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same')(a16)\n",
    "    \n",
    "     #Add batch Normalization\n",
    "    if batchNormalization:\n",
    "        c21 = BatchNormalization(axis=-1)(c21)\n",
    "    \n",
    "    a17 = Activation('relu')(c21)\n",
    "    \n",
    "    #final layer\n",
    "    c22 = Conv2D(final_neurons, kernel_size=(3,3), strides=(1,1), padding='same')(a17)\n",
    "    a18 = Activation(final_afun)(c22)\n",
    "    \n",
    "    model = Model(inputs,a18)\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plotter\n",
    "import matplotlib.pyplot as plt\n",
    "def plotter(History):\n",
    "    #Training vs Validation Learning loss \n",
    "    fig_loss = plt.figure(figsize=(4, 4))\n",
    "    plt.title(\"Learning curve\")\n",
    "    plt.plot(History.history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(History.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.argmin(History.history[\"val_loss\"]),\n",
    "             np.min(History.history[\"val_loss\"]),\n",
    "             marker=\"x\", color=\"r\", label=\"best model\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss Value\")\n",
    "    plt.legend(); \n",
    "\n",
    "    \n",
    "    #Train and test accuracy plot\n",
    "    fig_dice = plt.figure(figsize=(4,4))\n",
    "    plt.title(\"Dice Score Curve\")\n",
    "    plt.plot(History.history[\"dice_coef\"], label=\"dice_coef\")\n",
    "    plt.plot(History.history[\"val_dice_coef\"], label=\"val_dice_coef\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Dice Coef')\n",
    "    plt.legend(); \n",
    "\n",
    "\n",
    "    return fig_loss, fig_dice \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import SimpleITK as sitk\n",
    "def create_weight_map(mask, radius, i):\n",
    " \n",
    "    mask = np.uint16(mask)\n",
    "    # morphology kernel\n",
    "    kernel = np.ones((radius*2+1,radius*2+1))\n",
    "    \n",
    "    # dilate the mask -radius=2\n",
    "    dilate = cv2.dilate(mask, kernel)\n",
    "    \n",
    "    # erode the mask\n",
    "    erosion = cv2.erode(mask, kernel)\n",
    "    \n",
    "    # substract the eroded image from the dilated image\n",
    "    substraction = dilate-erosion\n",
    "    \n",
    "    # save the substraction\n",
    "   # cv2.imwrite('weight_map_{}.jpg'.format(i),substraction)\n",
    "    \n",
    "    #cv2.imshow('image', substraction)\n",
    "#    mask_dilated = sitk.GrayscaleDilate(mask,radius)\n",
    " #   mask_eroded = sitk.GrayscaleErode(mask,radius)\n",
    "  #  mask_boundary = sitk.Subtract(mask_dilated,mask_eroded)\n",
    "    \n",
    "    # save the substraction\n",
    "   # scipy.misc.imsave('weight_map_{}.jpg'.format(i),mask_boundary)\n",
    "\n",
    "    return substraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_loss(weight_map, weight_strength):\n",
    "    def weighted_dice_loss(y_true, y_pred):\n",
    "        y_true_f = K.flatten(y_true)\n",
    "        y_pred_f = K.flatten(y_pred)\n",
    "        weight_f = K.flatten(weight_map)\n",
    "        weight_f = weight_f * weight_strength\n",
    "        weight_f = 1/(weight_f+1)\n",
    "        weighted_intersection = K.sum(weight_f * (y_true_f * y_pred_f))\n",
    "        return -(2. * weighted_intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
    "    return weighted_dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_generator(gen1, gen2, gen3):\n",
    "     while True:\n",
    "        x = gen1.next()\n",
    "        y = gen2.next()\n",
    "        w = gen3.next()\n",
    "        yield([x, w], y)\n",
    "def generator_with_weights(x_train, y_train, weights_train, batch_size):\n",
    "    background_value = x_train.min()\n",
    "    data_gen_args = dict(rotation_range=10., width_shift_range=0.1, height_shift_range=0.1,\n",
    "    cval=background_value, zoom_range=0.2, horizontal_flip=True)\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    weights_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    image_generator = image_datagen.flow(x_train, shuffle=False, batch_size=batch_size,\n",
    "     seed=1)\n",
    "    mask_generator = mask_datagen.flow(y_train, shuffle=False, batch_size=batch_size,\n",
    "     seed=1)\n",
    "    weight_generator = weights_datagen.flow(weights_train, shuffle=False, batch_size=batch_size,\n",
    "     seed=1)\n",
    "    train_generator = combine_generator(image_generator, mask_generator, weight_generator)\n",
    "    return train_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/io/_io.py:48: UserWarning: `as_grey` has been deprecated in favor of `as_gray`\n",
      "  warn('`as_grey` has been deprecated in favor of `as_gray`')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: 0/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_TCIA_455_1_t1ce_133.png and mask /Lab1/Lab3/MRI/Mask/Brats17_TCIA_455_1_t1ce_133_Tumor.png\n",
      "Reading: 500/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_TCIA_168_1_t1ce_111.png and mask /Lab1/Lab3/MRI/Mask/Brats17_TCIA_168_1_t1ce_111_Tumor.png\n",
      "Reading: 1000/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_TCIA_370_1_t1ce_50.png and mask /Lab1/Lab3/MRI/Mask/Brats17_TCIA_370_1_t1ce_50_Tumor.png\n",
      "Reading: 1500/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_2013_10_1_t1ce_48.png and mask /Lab1/Lab3/MRI/Mask/Brats17_2013_10_1_t1ce_48_Tumor.png\n",
      "Reading: 2000/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_TCIA_372_1_t1ce_73.png and mask /Lab1/Lab3/MRI/Mask/Brats17_TCIA_372_1_t1ce_73_Tumor.png\n",
      "Reading: 2500/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_TCIA_150_1_t1ce_57.png and mask /Lab1/Lab3/MRI/Mask/Brats17_TCIA_150_1_t1ce_57_Tumor.png\n",
      "Reading: 3000/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_CBICA_BHK_1_t1ce_77.png and mask /Lab1/Lab3/MRI/Mask/Brats17_CBICA_BHK_1_t1ce_77_Tumor.png\n",
      "Reading: 3500/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_TCIA_165_1_t1ce_56.png and mask /Lab1/Lab3/MRI/Mask/Brats17_TCIA_165_1_t1ce_56_Tumor.png\n",
      "Reading: 4000/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_TCIA_370_1_t1ce_49.png and mask /Lab1/Lab3/MRI/Mask/Brats17_TCIA_370_1_t1ce_49_Tumor.png\n",
      "Reading: 4500/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_TCIA_274_1_t1ce_68.png and mask /Lab1/Lab3/MRI/Mask/Brats17_TCIA_274_1_t1ce_68_Tumor.png\n",
      "Reading: 5000/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_CBICA_AAL_1_t1ce_71.png and mask /Lab1/Lab3/MRI/Mask/Brats17_CBICA_AAL_1_t1ce_71_Tumor.png\n",
      "Reading: 5500/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_CBICA_ABM_1_t1ce_57.png and mask /Lab1/Lab3/MRI/Mask/Brats17_CBICA_ABM_1_t1ce_57_Tumor.png\n",
      "Reading: 6000/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_TCIA_474_1_t1ce_96.png and mask /Lab1/Lab3/MRI/Mask/Brats17_TCIA_474_1_t1ce_96_Tumor.png\n",
      "Reading: 6500/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_2013_2_1_t1ce_82.png and mask /Lab1/Lab3/MRI/Mask/Brats17_2013_2_1_t1ce_82_Tumor.png\n",
      "Reading: 7000/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_TCIA_412_1_t1ce_77.png and mask /Lab1/Lab3/MRI/Mask/Brats17_TCIA_412_1_t1ce_77_Tumor.png\n",
      "Reading: 7500/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_2013_3_1_t1ce_78.png and mask /Lab1/Lab3/MRI/Mask/Brats17_2013_3_1_t1ce_78_Tumor.png\n",
      "Reading: 8000/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_CBICA_AAG_1_t1ce_41.png and mask /Lab1/Lab3/MRI/Mask/Brats17_CBICA_AAG_1_t1ce_41_Tumor.png\n",
      "Reading: 8500/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_TCIA_222_1_t1ce_72.png and mask /Lab1/Lab3/MRI/Mask/Brats17_TCIA_222_1_t1ce_72_Tumor.png\n",
      "Reading: 9000/9403  of train images\n",
      "Readin image /Lab1/Lab3/MRI/Image/Brats17_2013_21_1_t1ce_89.png and mask /Lab1/Lab3/MRI/Mask/Brats17_2013_21_1_t1ce_89_Tumor.png\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import  Adam\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Model parameters\n",
    "base = 16\n",
    "image_size = 240\n",
    "img_ch = 1\n",
    "batch_size =8\n",
    "LR = 0.00001\n",
    "SDRate = 0.5\n",
    "batch_normalization = True\n",
    "spatial_dropout = True\n",
    "metric = 'dice'\n",
    "epochs = 150\n",
    "final_neurons= 1 #binary classification\n",
    "final_afun = \"sigmoid\" #activation function\n",
    "\n",
    "#Data loader parameters\n",
    "p = 0.2\n",
    "path = '/Lab1/Lab3/MRI/'\n",
    "fold1 = 'Image'\n",
    "fold2 = 'Mask'\n",
    "\n",
    "#Data augmentation parameters\n",
    "rotation_range = 10\n",
    "width_shift = 0.1\n",
    "height_shift_range = 0.1,\n",
    "rescale = 1./255\n",
    "horizontal_flip = True\n",
    "\n",
    "#K-fold cross validation\n",
    "n_folds = 3\n",
    "#Load the data\n",
    "\n",
    "images, masks, Weight_Map = get_train_test_data(fold1, fold2, path, p,image_size, image_size)\n",
    "\n",
    "#Data augmentation\n",
    "train_datagen, val_datagen = DataAugmentation(rotation_range,width_shift,height_shift_range,rescale,horizontal_flip)\n",
    "\n",
    "\n",
    "#Build the model\n",
    "model = u_net(base,image_size, image_size, img_ch, batch_normalization, SDRate, spatial_dropout,final_neurons, final_afun)\n",
    "print(\"model built\")\n",
    "#Compile the model\n",
    "model.compile(optimizer = Adam(lr=LR), loss = [dice_coef_loss], metrics =[dice_coef, Recall(), Precision()] )\n",
    "print(\"compiled!\")\n",
    " #k-fold crossvalidation loop\n",
    "cvscores = []\n",
    "cv = KFold(n_splits=3, random_state=42, shuffle=False)\n",
    "counter = 1\n",
    "\n",
    "for train_index, test_index in cv.split(images):\n",
    "    #train_test split\n",
    "    print('cross validation fold{}'.format(counter))\n",
    "    print(train_index)\n",
    "    x_train, x_val, y_train, y_val = images[train_index], images[test_index], masks[train_index], masks[test_index]\n",
    "\n",
    "    #Fit the data into the model\n",
    "   # History = model.fit(x_train, y_train, epochs = epochs, batch_size = batch_size, verbose = 1,\n",
    "      #                  validation_data = (x_val, y_val))\n",
    "    History = model.fit_generator(train_datagen.flow(x_train, y_train,batch_size = batch_size), validation_data = val_datagen.flow(x_val, y_val), epochs = epochs, verbose = 1)\n",
    "\n",
    "   # print(\"%s: %.2f%%\" % (model.metrics_names[1], History.history[\"val_dice_coef\"]))\n",
    "\n",
    "    fig_loss, fig_dice = plotter(History)\n",
    "    fig_loss.savefig('Deep-Learning-for-Medical-Application/Lab4/Plots/Task1/Learning_curve_Task{}_fold{}.png'.format(1,counter))\n",
    "    fig_dice.savefig('Deep-Learning-for-Medical-Application/Lab4/Plots/Task1/Dice_Score_Curve_Task{}_fold{}.png'.format(1,counter))\n",
    "    cvscores.append(History.history[\"val_dice_coef\"][len(History.history[\"val_dice_coef\"])-1])\n",
    "\n",
    "    counter=counter+1\n",
    "    History = None\n",
    "#print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_train_test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-030beef1700d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mweight_strength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#Load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#Data augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_train_test_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Main code\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#Model parameters\n",
    "base = 16\n",
    "image_size = 240\n",
    "img_ch = 1\n",
    "batch_size =8\n",
    "LR = 0.00001\n",
    "SDRate = 0.5\n",
    "batch_normalization = True\n",
    "spatial_dropout = True\n",
    "metric = 'dice'\n",
    "epochs = 150\n",
    "final_neurons= 1 #binary classification\n",
    "final_afun = \"sigmoid\" #activation function\n",
    "\n",
    "#Data loader parameters\n",
    "p = 0.2\n",
    "path = '/Lab1/Lab3/MRI/'\n",
    "fold1 = 'Image'\n",
    "fold2 = 'Mask'\n",
    "\n",
    "#Data augmentation parameters\n",
    "data_augmentation = True\n",
    "rotation_range = 10\n",
    "width_shift = 0.1\n",
    "height_shift_range = 0.1,\n",
    "rescale = 1./255\n",
    "horizontal_flip = True\n",
    "\n",
    "#K-fold cross validation\n",
    "n_folds = 3\n",
    "weight_strength = 1\n",
    "#Load the data\n",
    "images, masks, weight_maps = get_train_test_data(fold1, fold2, path, p,image_size, image_size)\n",
    "\n",
    "#Data augmentation\n",
    "train_datagen, val_datagen = DataAugmentation(rotation_range,width_shift,height_shift_range,rescale,horizontal_flip)\n",
    "\n",
    "\n",
    "#Build the model\n",
    "model = u_net(base,image_size, image_size, img_ch, batch_normalization, SDRate, spatial_dropout,final_neurons, final_afun)\n",
    "\n",
    "#k-fold crossvalidation loop\n",
    "for _ in range(n_folds):\n",
    "    #train_test split\n",
    "    x_train,x_val,y_train,y_val = train_test_split(images,masks,test_size = p, shuffle = False)\n",
    "    weight_train = weight_map[0:x_train.shape[0]-1][:,:]\n",
    "    weight_val = weight_map[x_train.shape[0]:][:,:]\n",
    "    #Compile the model\n",
    "    model.compile(optimizer = Adam(lr=LR), loss = weighted_loss(weight_maps, weight_strength), metrics =[dice_coef, Recall(), Precision()] )\n",
    "    if data_augmentation:\n",
    "        #Fit the data into the model\n",
    "        train_generator = generator_with_weights(x_train, y_train, weight_train, Batch_size)\n",
    "        History = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=epochs, \n",
    "                                            verbose=1, max_queue_size=1, validation_steps=len(x_val),\n",
    "                                            validation_data=([x_val, weight_val], y_val), shuffle=True, class_weight='auto')\n",
    "    else:\n",
    "        History = model.fit([x_train, weight_train], y_train, epochs = epochs, batch_size = batch_size, verbose = 1,\n",
    "                        validation_data = ([x_val, weight_val], y_val))\n",
    "        \n",
    "    \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], History.history[\"val_dice_coef\"]*100))\n",
    "    cvscores.append(History.history[\"val_dice_coef\"][len(History.history[\"val_dice_coef\"])-1] * 100)\n",
    "    plotter(History)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "T = 2 #number of cycles\n",
    "\n",
    "x_train,x_val,y_train,y_val = train_test_split(images,masks,test_size = p, shuffle = False)\n",
    "\n",
    "for s in range(T):\n",
    "    #train_test split\n",
    "    \n",
    "    weight_train = weight_map[0:x_train.shape[0]-1][:,:]\n",
    "    weight_val = weight_map[x_train.shape[0]:][:,:]\n",
    "    #Compile the model\n",
    "    model.compile(optimizer = Adam(lr=LR), loss = weighted_loss(weight_maps, weight_strength), metrics =[dice_coef, Recall(), Precision()] )\n",
    "    if data_augmentation:\n",
    "        #Fit the data into the model\n",
    "        train_generator = generator_with_weights(x_train, y_train, weight_train, Batch_size)\n",
    "        History = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=epochs, \n",
    "                                            verbose=1, max_queue_size=1, validation_steps=len(x_val),\n",
    "                                            validation_data=([x_val, weight_val], y_val), shuffle=True, class_weight='auto')\n",
    "    else:\n",
    "        History = model.fit([x_train, weight_train], y_train, epochs = epochs, batch_size = batch_size, verbose = 1,\n",
    "                        validation_data = ([x_val, weight_val], y_val))\n",
    "        \n",
    "    \n",
    "    val_predictions=model.predict(x_val,batch_size=int(batch_size/2))\n",
    "    train_predictions=model.predict(x_train,batch_size=int(batch_size/2))\n",
    "    \n",
    "    model_predictions[(s*1):((s+1)*1)] = val_predictions\n",
    "    \n",
    "    #Ask, we need to change the channels to 2\n",
    "\n",
    "    x_train,x_val,y_train,y_val = train_test_split(images,masks,test_size = p, shuffle = False)\n",
    "    \n",
    "    x_train=np.concatenate((x_train,train_predictions),axis=-1)\n",
    "    \n",
    "    x_val=np.concatenate((x_val,val_predictions),axis=-1)\n",
    "        \n",
    "    \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], History.history[\"val_dice_coef\"]*100))\n",
    "    cvscores.append(History.history[\"val_dice_coef\"][len(History.history[\"val_dice_coef\"])-1] * 100)\n",
    "    plotter(History)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
